<!DOCTYPE html>
<html>
<head>
    <title>Voice to Text with LUIS</title>
    <meta charset="utf-8" />
</head>
<body style="font-family:'Helvetica Neue',Helvetica,Arial,sans-serif; font-size:13px;">

    <table width="100%">
        <tr>
            <td></td>
            <td>
                <h1 style="font-weight:500;">Voice to Text with LUIS</h1>
               
            </td>
        </tr>
        <tr>            
            <td ><input  type="hidden" id="key" type="text" size="40" value="940c2da177274e9597b2b4ccfccb9620" v></td>
        </tr>
     
        </tr>
      
        </tr>
        <tr>
            <td></td>
            <td>
                <button id="startBtn" disabled="disabled">Start</button>
                <button id="stopBtn" disabled="disabled">Stop</button>
                
            </td>
        </tr>
        <tr>
            <td></td>
            <td>BING interpretation: <span id="hypothesisDiv"></span></td>
        </tr>
        <tr>
            <td></td>
            <td>
                <textarea id="phraseDiv" style="width:500px;height:200px"></textarea>
            </td>
        </tr>
        <tr>
            <td></td>
            <td>Status: <span id="statusDiv"></span></td>
        </tr>
    </table>

  
    <script src="scripts/require.min.js"></script>
    <script src="scripts/jquery.min.js"></script>
   

    <!-- SDK REFERENCE -->
    <script src="scripts/speech.browser.sdk-min.js"></script>

    <!-- SDK USAGE -->
    <script>
        // On doument load resolve the SDK dependecy
        function Initialize(onComplete) {
            require(["Speech.Browser.Sdk"], function(SDK) {
                onComplete(SDK);
            });
        }
        
        // Setup the recongizer
        function RecognizerSetup(SDK, recognitionMode, subscriptionKey) {
            var recognizerConfig = new SDK.RecognizerConfig(
                new SDK.SpeechConfig(
                    new SDK.Context(
                        new SDK.OS(navigator.userAgent, "Browser", null),
                        new SDK.Device("SpeechSample", "SpeechSample", "1.0.00000"))),
                recognitionMode
                ); 

           
            var authentication = new SDK.CognitiveSubscriptionKeyAuthentication(subscriptionKey);

            return SDK.CreateRecognizer(recognizerConfig, authentication);
        }

        // Start the recognition
        function RecognizerStart(SDK, recognizer) {
            recognizer.Recognize((event) => {
                /*
                 Alternative syntax for typescript devs.
                 if (event instanceof SDK.RecognitionTriggeredEvent)
                */
                switch (event.Name) {
                    case "RecognitionTriggeredEvent" :
                        UpdateStatus("Initializing");
                        break;
                    case "ListeningStartedEvent" :
                        UpdateStatus("Listening");
                        break;
                    case "RecognitionStartedEvent" :
                        UpdateStatus("Listening_Recognizing");
                        break;
                    case "SpeechStartDetectedEvent" :
                        UpdateStatus("Listening_DetectedSpeech_Recognizing");
                        console.log(JSON.stringify(event.Result)); // check console for other information in result
                        break;
                    case "SpeechHypothesisEvent" :
                        UpdateRecognizedHypothesis(event.Result.Text);
                        console.log(JSON.stringify(event.Result)); // check console for other information in result
                        break;
                    case "SpeechEndDetectedEvent" :
                        OnSpeechEndDetected();
                        UpdateStatus("Processing_Adding_Final_Touches");
                        console.log(JSON.stringify(event.Result)); // check console for other information in result
                        break;
                    case "SpeechSimplePhraseEvent" :
                        UpdateRecognizedPhrase(JSON.stringify(event.Result, null, 3));
                        break;
                    case "SpeechDetailedPhraseEvent" :
                        UpdateRecognizedPhrase(JSON.stringify(event.Result, null, 3));
                        break;
                    case "RecognitionEndedEvent" :
                        OnComplete();
                        UpdateStatus("Idle");
                        console.log(JSON.stringify(event)); // Debug information
                        break;
                }
            })
            .On(() => {
                // The request succeeded. Nothing to do here.
            },
            (error) => {
                console.error(error);
            });
        }

        // Stop the Recognition.
        function RecognizerStop(SDK, recognizer) {
            // recognizer.AudioSource.Detach(audioNodeId) can be also used here. (audioNodeId is part of ListeningStartedEvent)
            recognizer.AudioSource.TurnOff();
        }
    </script>

    <!-- Browser Hooks -->
    <script>
        var startBtn, stopBtn, hypothesisDiv, phraseDiv, statusDiv, key, languageOptions, formatOptions;
        var SDK;
        var recognizer;
        var previousSubscriptionKey;
        var input;
        var voices = speechSynthesis.getVoices();
        document.addEventListener("DOMContentLoaded", function () {
            createBtn = document.getElementById("createBtn");
            startBtn = document.getElementById("startBtn");
            stopBtn = document.getElementById("stopBtn");
            phraseDiv = document.getElementById("phraseDiv");
            hypothesisDiv = document.getElementById("hypothesisDiv");
            statusDiv = document.getElementById("statusDiv");
            key = document.getElementById("key");
         

            startBtn.addEventListener("click", function () {
                if (!recognizer || previousSubscriptionKey != key.value) {
                    previousSubscriptionKey = key.value;
                    Setup();
                }

                hypothesisDiv.innerHTML = "";
                phraseDiv.innerHTML = "";
                RecognizerStart(SDK, recognizer);
                startBtn.disabled = true;
                stopBtn.disabled = false;
            });

            stopBtn.addEventListener("click", function () {
                RecognizerStop(SDK);
                startBtn.disabled = false;
                stopBtn.disabled = true;
            });

            Initialize(function (speechSdk) {
                SDK = speechSdk;
                startBtn.disabled = false;
                voiceoutput("Hello! I'm your voice assistant,how can i help you ?")
            });
        });
        function voiceoutput(text){
            if('speechSynthesis' in window){

                //var voices = speechSynthesis.getVoices();
      //for(var i = 0; i < voices.length; i++ ) {
        //console.log("Voice " + i.toString() + ' ' + voices[i].name + ' ' + voices[i].uri);
      //}
    var speech = new SpeechSynthesisUtterance(text);
    speech.lang = 'en-US';
    speech.voice = voices[4]
    window.speechSynthesis.speak(speech);
            activatestart();     
}
        } 
         function voiceoutput_detection(text){

            if('speechSynthesis' in window){
    var speech = new SpeechSynthesisUtterance(text);
    speech.lang = 'en-US';

    
     
    speech.voice = voices[4]

    window.speechSynthesis.speak(speech);
            activatestart();  
            UpdateRecognizedHypothesisUserConfirmation(text);   
}
        } 
        function activatestart()
        {   
            $(startBtn).click() 
            $(startBtn).hide()
            $(stopBtn).hide()
           
        }
        function Setup() {
            recognizer = RecognizerSetup(SDK, SDK.RecognitionMode.Interactive, key.value);
        }

        function UpdateStatus(status) {
            statusDiv.innerHTML = status;
        }

        function UpdateRecognizedHypothesis(text) {
            hypothesisDiv.innerHTML = text;
          
            input = text;
             if(text =="yes")
            {
                alert("Call Tableau Dashboard");
                voiceoutput("Filtering the entities for Tableau")
                activatestart();
            }
            else
            {
                //alert("speak again");
            }
            
        }
        function UpdateRecognizedHypothesisUserConfirmation(text) {
            hypothesisDiv.innerHTML = text;
            if(text =="yes")
            {
                //alert("Call Tableau Dashboard");
                activatestart();
            }
            else
            {
                //alert("speak again");
            }
            input = text;
        }

        function OnSpeechEndDetected() {
            stopBtn.disabled = true;
        }

        function UpdateRecognizedPhrase(json) {
            $.get("https://westus.api.cognitive.microsoft.com/luis/v2.0/apps/5cac76d5-cdf5-4928-a48e-3fc400c5430a?subscription-key=15e9c635dabb4b17a699da23564be8b6&timezoneOffset=0&verbose=true&q="+input+"",
                function(data){
                 phraseDiv.innerHTML =  JSON.stringify(data);
                 try{
                     voice_text = "Detected" +JSON.stringify(data.entities[0].entity)+JSON.stringify(data.entities[0].type) + "Do you want to proceed?";
                     voiceoutput_detection(voice_text)
                 }
                 catch(err)
                 {
                    
                 }

                 //JSON.stringify(data.entities[0].type )+ ":"+ JSON.stringify(data.entities[0].entity);
                });

    };
        
        function OnComplete() {
            startBtn.disabled = false;
            stopBtn.disabled = true;
        }
       
          
    </script>
</body>
</html>
